{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAS (Neural Architecture Search) for Classification on Vertex AI with TF-vision\n",
    "\n",
    "Make sure that you have read the [required documentations](https://cloud.google.com/vertex-ai/docs/training/neural-architecture-search/overview#reading_order)\n",
    "before executing this notebook.\n",
    "NOTE: This notebook is meant to run pre-built trainer code with pre-built search-spaces. If you want to run your own trainer\n",
    "code or create your own NAS search-space from scratch, then do not use this notebook.\n",
    "\n",
    "This notebook shows example of [MnasNet](https://arxiv.org/abs/1807.11626) paper result on Imagenet data.\n",
    "According to the paper, MnasNet achieves 75.2% top-1 accuracy with 78ms latency on a Pixel phone, \n",
    "which is 1.8x faster than MobileNetV2 with 0.5% higher accuracy and 2.3x faster than NASNet with 1.2% higher accuracy.\n",
    "However, this notebook uses GPUs instead of TPUs for training and uses A100 80GB GPUs (a2-ultragpu-2) to evaluate latency.\n",
    "With this notebook, the expected Stage2 top-1 accuracy on MNasnet is 75.2% with 50ms latency on A100 80GB GPUs (a2-ultragpu-2)).\n",
    "The detailed settings for this notebook are:\n",
    "- Stage-1 search\n",
    "    - Number of trials: 10000\n",
    "    - Number of GPUs per trial: 2\n",
    "    - GPU type: NVIDIA_A100_80GB\n",
    "    - Avg single trial training time: 1.5 hours\n",
    "    - Number of parallel trials: 50\n",
    "    - GPU quota used: 50*2 = 100 A100 80GB GPUs\n",
    "    - Time to run: 7 days\n",
    "\n",
    "- Stage-2 full-training with top 10 models\n",
    "    - Number of trials: 10\n",
    "    - Number of GPUs per trial: 2\n",
    "    - GPU type: NVIDIA_A100_80GB\n",
    "    - Avg single trial training time: 7 days\n",
    "    - Number of parallel trials: 10\n",
    "    - GPU quota used: 10*2 = 20 A100 80GB GPUs\n",
    "\n",
    "\n",
    "You can also test drive MnasNet with just few trials with much lower cost.\n",
    "See [here for the test drive settings and cost](https://cloud.google.com/vertex-ai/docs/training/neural-architecture-search/overview#mnasnet_test_drive).\n",
    "For this use case, run this notebook only till section 'Sanity Check: Launch NAS stage 1 job with latency constraint'.\n",
    "\n",
    "\n",
    "Here are the **pre-requisites** before you can start using this notebook: \n",
    "1. Your GCP project should have been (a) allow-listed and (b) [DWS GPU quota should have been allocated](https://cloud.google.com/vertex-ai/docs/training/neural-architecture-search/environment-setup#device-quota) for the NAS jobs.\n",
    "2. You have selected a python3 kernel to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "pip install tensorflow==2.7.0 --user\n",
    "pip install tf-models-official==2.7.1\n",
    "pip install pyglove==0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: Please restart the notebook after installing above libraries successfully.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download source code\n",
    "\n",
    "This needs to be done just once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# NOTE: It is ok for this step to fail if the directory exists.\n",
    "mkdir -p ~/nas_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "rm -r -f ~/nas_experiment/nas_codes\n",
    "git clone https://github.com/google/vertex-ai-nas.git ~/nas_experiment/nas_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set code path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.join('/home/jupyter/nas_experiment/nas_codes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment variables\n",
    "\n",
    "Here we set up the environment variables.\n",
    "\n",
    "NOTE: These have to be set-up every time you run a new session because the later code-blocks use them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set a unique USER name. This is used for creating a unique job-name identifier.\n",
    "%env USER=<user>-nas\n",
    "# Set a region to launch jobs into.\n",
    "# If you only want to test-drive and do not have enough GPU quota, then you can use 'us-central1' region\n",
    "# which should have a default quota of 12 Nvidia T4 GPUs.\n",
    "%env REGION=us-central1\n",
    "# Set any unique docker-id for this run. When the next section builds a docker, then this id will be used to tag it.\n",
    "%env TRAINER_DOCKER_ID=<user>-nas-trainer-dockerid\n",
    "%env LATENCY_CALCULATOR_DOCKER_ID=<user>-nas-calc-dockerid\n",
    "# The GCP project-id must be the one that has been clear-listed for the NAS jobs. \n",
    "%env PROJECT_ID=<project_id>\n",
    "# Set an output working directory for the NAS jobs. The GCP project should have write access to \n",
    "# this GCS output directory. A simple way to ensure this is to use a bucket inside the same GCP project.\n",
    "# NOTE: The region of the bucket must be the same as job's.\n",
    "%env GCS_ROOT_DIR=<GCS directory to place results>\n",
    "# Set the accelerator device type.\n",
    "%env DEVICE=NVIDIA_A100_80GB\n",
    "# Set the GCS paths to the training and validation datasets. The GCP project should have read access to the data-location.\n",
    "# Please read the \"Data-Preparation\" section \n",
    "# (https://cloud.google.com/vertex-ai/docs/training/neural-architecture-search/pre-built-trainer#data-preparation)\n",
    "# in the documentation to ensure that the data is in an appropriate format\n",
    "# suitable for the NAS pipeline. The documentation also mentions how you can download and prepare the ImageNet dataset.\n",
    "# You can run the \"Validate and Visualize data format\" section in this notebook \n",
    "# to verify that the data can be loaded properly.\n",
    "# Update the path to ImageNet data below.\n",
    "%env STAGE1_TRAINING_DATA_PATH=<imagenet-data-gs-path>/classification/imagenet/train-00[0-8]??-of-01024\n",
    "%env STAGE1_VALIDATION_DATA_PATH=<imagenet-data-gs-path>/classification/imagenet/train-009??-of-01024,gs://cloud-nas-public-eu/classification/imagenet/train-01???-of-01024\n",
    "%env STAGE2_TRAINING_DATA_PATH=<imagenet-data-gs-path>/classification/imagenet/train*\n",
    "%env STAGE2_VALIDATION_DATA_PATH=<imagenet-data-gs-path>/classification/imagenet/validation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The following set up steps need to be done just once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Authenticate docker for your artifact registry.\n",
    "gcloud auth configure-docker ${REGION}-docker.pkg.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# NOTE: This needs to be just once for the first time. It is ok for this to FAIL if the GCS bucket already exists.\n",
    "\n",
    "# Create the output directory. \n",
    "gsutil mkdir $GCS_ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build container\n",
    "The container must be built the first time and then every time the source-code is modified. Otherwise, there is no need to run this step. This step internally builds the *Dockerfile* in the source-code directory and then pushes the docker to the cloud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# NOTE: This step can take several minutes when run for the first time.\n",
    "\n",
    "python3 vertex_nas_cli.py build \\\n",
    "--project_id=${PROJECT_ID} \\\n",
    "--trainer_docker_id=${TRAINER_DOCKER_ID} \\\n",
    "--region=${REGION} \\\n",
    "--trainer_docker_file=\"tf_vision/nas_multi_trial.Dockerfile\" \\\n",
    "--latency_calculator_docker_id=${LATENCY_CALCULATOR_DOCKER_ID} \\\n",
    "--latency_calculator_docker_file=\"tf_vision/latency_computation_using_saved_model.Dockerfile\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check: Launch NAS stage 1 job with latency constraint\n",
    "If you do not want to run a full MNasNet run and only want to test drive with [just few trials as described here,](https://cloud.google.com/vertex-ai/docs/training/neural-architecture-search/overview#mnasnet_test_drive)\n",
    "then only run the following command and skip the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "DATE=\"$(date '+%Y%m%d_%H%M%S')\"\n",
    "JOB_ID=\"${USER}_nas_tfvision_icn_latency_${DATE}\"\n",
    "\n",
    "\n",
    "# GPU configs\n",
    "# https://cloud.google.com/vertex-ai/docs/training/configure-compute#specifying_gpus\n",
    "\n",
    "\n",
    "CMD=\"\n",
    "python3 vertex_nas_cli.py search \\\n",
    "--project_id=${PROJECT_ID} \\\n",
    "--region=${REGION} \\\n",
    "--trainer_docker_id=${TRAINER_DOCKER_ID} \\\n",
    "--job_name=${JOB_ID} \\\n",
    "--max_nas_trial=10 \\\n",
    "--max_parallel_nas_trial=10 \\\n",
    "--max_failed_nas_trial=10 \\\n",
    "--use_prebuilt_trainer=True \\\n",
    "--prebuilt_search_space=\"mnasnet\" \\\n",
    "--master_machine_type=\"a2-ultragpu-2g\" \\\n",
    "--accelerator_type=${DEVICE} \\\n",
    "--num_gpus=2 \\\n",
    "--root_output_dir=${GCS_ROOT_DIR} \\\n",
    "--latency_calculator_docker_id=${LATENCY_CALCULATOR_DOCKER_ID} \\\n",
    "--target_device_type=CPU \\\n",
    "--use_prebuilt_latency_calculator=True \\\n",
    "--search_docker_flags \\\n",
    "params_override=\"tf_vision/configs/experiments/mnasnet_search_gpu.yaml\" \\\n",
    "training_data_path=${STAGE1_TRAINING_DATA_PATH} \\\n",
    "validation_data_path=${STAGE1_VALIDATION_DATA_PATH} \\\n",
    "model=\"classification\" \\\n",
    "target_device_latency_ms=50\n",
    "\"\n",
    "\n",
    "echo Executing command: ${CMD}\n",
    "    \n",
    "${CMD}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Experiment: Launch NAS stage 1 job with latency constraint\n",
    "If you do not want to run a full MNasNet run and only want to test drive with [just few trials as described here,](https://cloud.google.com/vertex-ai/docs/training/neural-architecture-search/overview#mnasnet_test_drive)\n",
    "then only run the following command and skip the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "DATE=\"$(date '+%Y%m%d_%H%M%S')\"\n",
    "JOB_ID=\"${USER}_nas_tfvision_icn_latency_${DATE}\"\n",
    "\n",
    "\n",
    "# GPU configs\n",
    "# https://cloud.google.com/vertex-ai/docs/training/configure-compute#specifying_gpus\n",
    "\n",
    "\n",
    "CMD=\"\n",
    "python3 vertex_nas_cli.py search \\\n",
    "--project_id=${PROJECT_ID} \\\n",
    "--region=${REGION} \\\n",
    "--trainer_docker_id=${TRAINER_DOCKER_ID} \\\n",
    "--job_name=${JOB_ID} \\\n",
    "--max_nas_trial=10000 \\\n",
    "--max_parallel_nas_trial=30 \\\n",
    "--max_failed_nas_trial=3000 \\\n",
    "--use_prebuilt_trainer=True \\\n",
    "--prebuilt_search_space=\"mnasnet\" \\\n",
    "--master_machine_type=\"a2-ultragpu-2g\" \\\n",
    "--accelerator_type=${DEVICE} \\\n",
    "--num_gpus=2 \\\n",
    "--root_output_dir=${GCS_ROOT_DIR} \\\n",
    "--latency_calculator_docker_id=${LATENCY_CALCULATOR_DOCKER_ID} \\\n",
    "--target_device_type=CPU \\\n",
    "--use_prebuilt_latency_calculator=True \\\n",
    "--search_docker_flags \\\n",
    "params_override=\"tf_vision/configs/experiments/mnasnet_search_gpu.yaml\" \\\n",
    "training_data_path=${STAGE1_TRAINING_DATA_PATH} \\\n",
    "validation_data_path=${STAGE1_VALIDATION_DATA_PATH} \\\n",
    "model=\"classification\" \\\n",
    "target_device_latency_ms=50\n",
    "\"\n",
    "\n",
    "echo Executing command: ${CMD}\n",
    "    \n",
    "${CMD}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume NAS stage 1 job with latency constraint\n",
    "You can find the nas_job_id and latency_job_id numbers from the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "previous_nas_job_id=<fill>\n",
    "previous_latency_job_id=<fill>\n",
    "DATE=\"$(date '+%Y%m%d_%H%M%S')\"\n",
    "JOB_NAME=\"${USER}_nas_tfvision_icn_latency_${DATE}\"\n",
    "\n",
    "\n",
    "CMD=\"python3 vertex_nas_cli.py search_resume \\\n",
    "  --project_id=${PROJECT_ID} \\\n",
    "  --region=${REGION} \\\n",
    "  --job_name=${JOB_NAME} \\\n",
    "  --previous_nas_job_id=${previous_nas_job_id} \\\n",
    "  --previous_latency_job_id=${previous_latency_job_id} \\\n",
    "  --root_output_dir=${GCS_ROOT_DIR} \\\n",
    "  --max_nas_trial=2 \\\n",
    "  --max_parallel_nas_trial=2 \\\n",
    "  --max_failed_nas_trial=2\"\n",
    "echo Executing command: ${CMD}\n",
    "    \n",
    "${CMD}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect NAS search progress\n",
    "A periodic evaluation while the search is going on can help decide if the search job has converged. This code-block shows how to generate summary of top N trials so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the stage1 search-job id. It's a numeric value returned by the Vertex service.\n",
    "%env JOB_ID=<fill>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "mkdir -p /home/jupyter/nas_experiment/jobs\n",
    "python3 vertex_nas_cli.py list_trials \\\n",
    "--project_id=${PROJECT_ID} \\\n",
    "--job_id=${JOB_ID} \\\n",
    "--region=${REGION} \\\n",
    "--trials_output_file=/home/jupyter/nas_experiment/jobs/${JOB_ID}.yaml\n",
    "\n",
    "cat /home/jupyter/nas_experiment/jobs/${JOB_ID}.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch NAS stage 2 job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "DATE=\"$(date '+%Y%m%d_%H%M%S')\"\n",
    "\n",
    "# Please modify the \"JOB_ID\", \"TRIAL_ID\", and the finetuning config file before running.\n",
    "# JOB_ID is numeric value you can find from the job UI in Pantheon.\n",
    "JOB_ID=<fill>\n",
    "# TRIAL_ID is one of the best performing trials which has to be finetuned.\n",
    "TRIAL_IDS=<fill> # The top trials chosen for training to converge.\n",
    "\n",
    "CMD=\"\n",
    "\n",
    "python3 vertex_nas_cli.py train \\\n",
    "--project_id=${PROJECT_ID} \\\n",
    "--region=${REGION} \\\n",
    "--trainer_docker_id=${TRAINER_DOCKER_ID} \\\n",
    "--use_prebuilt_trainer=True \\\n",
    "--prebuilt_search_space=\"mnasnet\" \\\n",
    "--train_accelerator_type=${DEVICE} \\\n",
    "--train_num_gpus=4 \\\n",
    "--root_output_dir=${GCS_ROOT_DIR} \\\n",
    "--search_job_id=${JOB_ID} \\\n",
    "--search_job_region=${REGION} \\\n",
    "--train_nas_trial_numbers=${TRIAL_IDS} \\\n",
    "--train_job_suffix=\"stage2_${DATE}\" \\\n",
    "--train_docker_flags \\\n",
    "params_override=\"tf_vision/configs/experiments/mnasnet_search_finetune_gpu.yaml\" \\\n",
    "training_data_path=${STAGE2_TRAINING_DATA_PATH} \\\n",
    "validation_data_path=${STAGE2_VALIDATION_DATA_PATH} \\\n",
    "model=\"classification\"\n",
    "\"\n",
    "\n",
    "echo Executing command: ${CMD}\n",
    "    \n",
    "${CMD}"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
